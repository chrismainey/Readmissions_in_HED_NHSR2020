---
title: "Modelling Readmission in HED"
subtitle: "using R"
author: "Chris Mainey"
date: "2020/10/19 (updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    css: HED.css
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
    seal: false

---
class: title-slide

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  fig.height=6
  , fig.width=10
  , fig.align = "center"
	, dev.args = list(png = list(type = "cairo"))
)
 
library(Cairo)
library(tidyverse)
#library(metallicaRt)

theme_set(
  theme_minimal()+
  theme(text = element_text(family = "Open Sans"))
)


set.seed(123)
X <- c(runif(50, 0, 5), 0)
Y <- 2 + (1.5 * X[1:50]) + rnorm(50, 0, 0.5)
Y[51] <- 2
my_data <- data.frame(X, Y)
rm(list = c('X','Y'))
X <- c(2,3,3)
Y <- 2 + (1.5 * X)
Y[2] <- Y[1]
Y[3] <- Y[3] +0.05
dt2 <- data.frame(X, Y)
rm(list = c('X','Y'))
triangle<- data.frame(X=c(2.5, 3.2, 0),
Y = c(4.5, 5.8, 2.9), 
value=c("1", "1.5", "2"),
label= c("1", "\u03B2", "\u03B1" ))
```

<br><br><br>

# Modelling HES data in R: Readmissions

<br><br>

.pull-left[
__Chris Mainey__
<b><p style="font-size:26;">Senior Data Scientist<br>
University Hospitals Birmingham 
NHS FT</b></p>
<br>
<span style="font-size:26;">[chris.mainey@uhb.nhs.uk](mailto:chris.mainey@uhb.nhs.uk)</span><br>
`r icon::fa("twitter", color=rgb(148, 198, 0, maxColorValue = 255))` <a href="https://twitter.com/chrismainey?s=09" style="line-height:2;">@chrismainey</a>
]

.pull-right[
<img src= "https://chrismainey.github.io/EARL_2019_presentation/assets/HI.png" width=75% height=75%>
<br>
<img src= "https://chrismainey.github.io/EARL_2019_presentation/assets/logo.png" width=65% height=65%>
]

---

# Healthcare Evaluation Data (HED)


<a href="https://www.hed.nhs.uk">www.hed.nhs.uk </a>


.pull-left[
- Online hospital benchmarking system
- Statistical models and analysis tools
- Activity, Mortality, Re-admissions, Length-of-Stay, Market-share etc.
- Run by University Hospitals Birmingham NHS FT
- Used by ~60 NHS and other organisations
- Training and support
<br><br>
- __Using national NHS data, including HES, ONS mortality, central returns, NRLS and others__
]
.pull-right[
<br>
<img src="https://chrismainey.github.io/EARL_2019_presentation/assets/HED_system.png">
]

---

# Casemix-adjusted indicators

__Leading question:__ _How can we compare indicators like readmissions or mortality across units?_
<br>

+ Different patients at different levels of risk.

--

+ Aggregated data can also lead to different size 'bins'

--

+ Conceivable that different mixed due to factors like:
 + Age profiles
 + Elective / Non-elective balance
 + Types of services at sites
 + Seasonality

--

+ Important to understand biases associated with (and without) adjustment

---

# Performing casemix adjustment

+ Various ways, but we focus on __indirectly-standardised ratios__

--

+ Adjust all to the expected average risks

--

+ Commonly use a regression model to predict risk.

--

+ Relative risk ratio is then:

$$ \frac{\sum{events}}{\sum{risk}}$$
+ We can then predict a risk score from patient demographics and admission details.

---

## Case-study
### Relative-Risk Readmission Ratio

Readmission to any acute provider within 30-days of discharge from another. Indexed to dishcarge form the first organisation.

--

+ Major variables relate to age, sex, admission method, diagnosis, comorbid conditions.

--

+ How we parametrise these variables affects quality of model.
 + E.g. Age as continuous?  Assumes affects of age constant.
 + What if it's not? Binning or transformations?

--

+ Regression assumes all points are independent, this is not true here:
 + Patients at hospital X more like 'hospital X' patient than 'average patient'
 + Clustering

---

# Non-linear data:
What if the relationship between X and Y varies across the range?

---

```{r sig, echo=FALSE, message=TRUE, warning=FALSE}
### Sigmoid function ### create a function to generate sigmoid pattern
sigmoid <- function(x, lower_asymptote, carrying_capacity, growth_rate, time_max) {
  return(lower_asymptote + ((carrying_capacity - lower_asymptote)/(1 + exp(-growth_rate * 
                                                                             (x - time_max)))))
}
X <- 1:100
X <- c(X, X+rnorm(X,X,2), X+rnorm(X, X, 5))
Y <- sigmoid(1:100, 1, 50, 0.2, 50) + rnorm(100, 0, 5)
Y <- c(Y, Y+rnorm(Y, Y, 3), Y+rnorm(Y, Y, 8))
dt<-data.frame(X,Y)
dt$cat<-factor(ifelse(dt$X<50, "a", ifelse(dt$X <150, "b", "c")))
dt$cat_pred<-predict(lm(dt$Y ~ dt$cat))


ggplot(dt, aes(y=Y, x=X))+
  geom_point(size=1.5, alpha=0.4)+
  theme(axis.title.y = element_text(vjust = 0.5,angle=0))

```


---

# What about nonlinear data? (2)

```{r cats, echo=FALSE, message=FALSE, warning=FALSE, fig.height=6.5}
ggplot(dt, aes(y=Y, x=X))+
  geom_point(size=1.8, alpha=0.4)+
  geom_smooth(aes(col="A"), method = "lm",  se=FALSE, size=1.3)+
  #geom_line(aes(y=cat_pred, col="B"),  size=1.3)+
  #geom_smooth(aes(col="C"), method = "lm", formula= y~poly(x, 3),  se=FALSE, size=1.3)+
  scale_color_manual(values = c("#5DDEDE", "#FAD74B" ,"#FA6767"),
                     labels= factor(x=c("A", "B", "C"), levels=c("A", "B", "C"), labels=c("Linear", "Categorical", "Polynomial"), ordered=TRUE)
                     , name="Type of fit")+
  #ggtitle("Varying approximations for non-linear relationships")+
  theme(legend.position = "bottom",
        legend.title = element_text(face="bold", size=10),
        legend.text = element_text(size=9),
        plot.title = element_text(size = 12, face="bold") )
```
---

# What about nonlinear data? (3)

```{r cats3, echo=FALSE, message=FALSE, warning=FALSE, fig.height=6.5}
ggplot(dt, aes(y=Y, x=X))+
  geom_point(size=1.8, alpha=0.4)+
  #geom_smooth(aes(col="A"), method = "lm",  se=FALSE, size=1.3)+
  geom_line(aes(y=cat_pred, col="B"),  size=1.3)+
  #geom_smooth(aes(col="C"), method = "lm", formula= y~poly(x, 3),  se=FALSE, size=1.3)+
  scale_color_manual(values = c("#FAD74B" ,"#FA6767"),
                     labels= factor(x=c("B", "C"), levels=c("B", "C"), labels=c("Categorical", "Polynomial"), ordered=TRUE)
                     , name="Type of fit")+
  #ggtitle("Varying approximations for non-linear relationships")+
  theme(legend.position = "bottom",
        legend.title = element_text(face="bold", size=10),
        legend.text = element_text(size=9),
        plot.title = element_text(size = 12, face="bold") )
```
---

# What about nonlinear data? (4)

```{r cats4, echo=FALSE, message=FALSE, warning=FALSE, fig.height=6.5}
ggplot(dt, aes(y=Y, x=X))+
  geom_point(size=1.8, alpha=0.4)+
  #geom_smooth(aes(col="A"), method = "lm",  se=FALSE, size=1.3)+
  #geom_line(aes(y=cat_pred, col="B"),  size=1.3)+
  geom_smooth(aes(col="C"), method = "lm", formula= y~poly(x, 3),  se=FALSE, size=1.3)+
  scale_color_manual(values = c("#FA6767"),
                     labels= factor(x=c("C"), levels=c("C"), labels=c("Polynomial"), ordered=TRUE)
                     , name="Type of fit")+
  #ggtitle("Varying approximations for non-linear relationships")+
  theme(legend.position = "bottom",
        legend.title = element_text(face="bold", size=10),
        legend.text = element_text(size=9),
        plot.title = element_text(size = 12, face="bold") )
```
---

# What about nonlinear data? (5)

```{r cats5, echo=FALSE, message=FALSE, warning=FALSE, fig.height=6.5}
ggplot(dt, aes(y=Y, x=X))+
  geom_point(size=1.8, alpha=0.4)+
  geom_smooth(aes(col="A"), method = "lm",  se=FALSE, size=1.3)+
  geom_line(aes(y=cat_pred, col="B"),  size=1.3)+
  geom_smooth(aes(col="C"), method = "lm", formula= y~poly(x, 3),  se=FALSE, size=1.3)+
  scale_color_manual(values = c("#5DDEDE", "#FAD74B" ,"#FA6767"),
                     labels= factor(x=c("A", "B", "C"), levels=c("A", "B", "C"), labels=c("Linear", "Categorical", "Polynomial"), ordered=TRUE)
                     , name="Type of fit")+
  #ggtitle("Varying approximations for non-linear relationships")+
  theme(legend.position = "bottom",
        legend.title = element_text(face="bold", size=10),
        legend.text = element_text(size=9),
        plot.title = element_text(size = 12, face="bold") )
```

---
# GAMs + Splines

+ Smooth, piece-wise polynomials, like a flexible strip for drawing curves.
+ 'Knot points' between each section
+ Then ;Generalised Additive Model as regression on the sum of smoothers

```{r gam1, echo=FALSE, fig.height=5, fig.width=9, message=FALSE, warning=FALSE}
library(splines)
ggplot(dt, aes(y=Y, x=X))+
  geom_point(size=1.5, alpha=0.4)+
  geom_smooth(aes(col="A"), method = "lm", formula = y~ns(x,10), se=FALSE, size=1.2, show.legend = FALSE)
```


---

# GAMs in R

Prof. Simon Wood's package is de-facto standard

```{r gam}
library(mgcv)
my_gam <- gam(Y ~ s(X, bs="cr"), data=dt)
```

+ `s()` control smoothers
+ `bs="cr"` telling it to use cubic regression spline ('basis')
+ Default is 10 knots (`k=10` argument), but you can alter this
---

# Model Output:
```{r gam2}
summary(my_gam)
```

---
class: middle
# Clustering
Data collected in unit/centrers, not at random in the population

---
# 'Random effects'

```{r setuprint, echo=FALSE, message = FALSE,	warning = FALSE, include = FALSE}
set.seed(123)
dfc<-data.frame(
  clust=as.factor(replicate(n = 100, c("A", "B","C", "D", "E"))),
  x=rnorm(500,mean = 5, sd= 2))
  
dfc$y1<- dfc$x+ jitter(50 * dfc$x, amount = 20)
dfc$y<- dfc$y1 + jitter(as.numeric(dfc$clust))^3

library(lme4)
ri<-lmer(y~x+(1|clust), data=dfc)
fe<-lm(y~x, data=dfc)
fe2<-glm(y~x, data=dfc, family="gaussian")

library(sjPlot)
library(sjmisc)
library(sjlabelled)

res<-get_model_data(ri, type="re")[c(5,1)]
z<-data.frame(as.factor(rownames(coef(ri)[[1]])), coef(ri)[[1]], alpha= 49.88)
names(z) <- c("cluster", "rint","int","slope")
z$newint <- res$estimate + z$int
```

Lets image when have a big cloud of data points: 

```{r rint1, echo=FALSE}
ggplot(dfc, aes(x=x,y=y))+
  geom_point()+
  stat_smooth(method=lm, formula = y~x, col="red")+
  ggtitle("Scatter plot of made-up example, with Y predicted by X")
```

---

# Random effects (2)

If we assume all points are independent, the previous model was fine, but...

```{r rint2, echo=FALSE}
ggplot(dfc, aes(x=x,y=y))+
  geom_point(aes(col=clust))+
  stat_smooth(method=lm, formula = y~x, col="red") +
  scale_colour_viridis_d(alpha=0.8)+
  ggtitle("...what if the data are repeated measures from clusters")+
  labs(color='Cluster')
```

---

# Random effects (3)

If we assume all points are independent, the previous model was fine, but...

```{r rint3, echo=FALSE}
ggplot(dfc, aes(x=x,y=y))+
  geom_point(aes(col=clust))+
  geom_abline(aes(intercept=newint, slope=slope, col=cluster), lwd=1, data=z)+
  stat_smooth(method=lm, formula = y~x, col="red") +
  scale_colour_viridis_d(alpha=0.8)+
  ggtitle("Random-intercepts for clusters")+
  labs(color='Cluster')
```

---

# Random effects (4)

So we end up with a 'random-intercept' model:

```{r rintmod}
library(lme4)
my_ri_model<-lmer(y~x+(1|clust), data=dfc)

summary(my_ri_model)
```


---

# ...but HES is pretty big, right?

YES!  Yes it is, so required special handling;

+ Memory efficiency and speed - `data.table` package
+ Only load section required for each model:
 + Use database (SQL Server) for what it's designed for!
 + Stratified by each HRG4 sub-chapter
 + Sparse model matrix
+ Parallelisation - `doParallel` - better on Linux, speaking of which:
+ Linux! - Set up a VM on server, RStudio Server.
+ Optimised functions, like `bam()` in `mgcv`

---

# Journey in HED

+ HED used SAS for many years to build regression models.
+ CM had PhD project funded by UHB that allowed space to learn `R`
+ CM was useless for the first 18-months!
+ Then translated 'broken' SAS models to `R`
+ Initially CM's (reasonable scripts)
+ Not sustainable: couldn't pass to other analysts, not fault tolerant, no metadata
+ Built R package - MB primarily translated scripts
+ R package building encouraged use of Git source control
+ Model management database, powered by functions in `R` package

---

# Making it happen

Didn't happen over night!

+ Organisation move slowly
+ Your enthusiasm is a good start, but it's not the end
+ Don't assume others can see the benefits
 + Technical talk is intimidating if you are not part of it!
 + Sell benefits
 + Work out timescale and costs (time, as much as financial)

